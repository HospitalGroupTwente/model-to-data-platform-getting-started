services:
  mlflow-server:
    restart: always
    build: 
      dockerfile: mlflow
      context: docker_scripts
    container_name: mlflow_server
    network_mode: "host"
    working_dir: /app
    command: mlflow server --default-artifact-root /tmp/ --no-serve-artifacts --host 0.0.0.0 --port 3001 

  submission_run:
    build: 
      dockerfile: execute_code 
      context: docker_scripts
    container_name: code_submission 
    network_mode: "host"
    working_dir: /app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: python3 /main.py
    depends_on:
      - mlflow-server
    volumes:
      - export:/mnt/export/
      - /dataset:/mnt/dataset/

volumes:
  export:
